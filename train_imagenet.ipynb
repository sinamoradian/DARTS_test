{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import utils\n",
    "import glob\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import genotypes\n",
    "import torch.utils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from model import NetworkImageNet as Network\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\"imagenet\")\n",
    "parser.add_argument('--data', type=str, default='../data/imagenet/', help='location of the data corpus')\n",
    "parser.add_argument('--batch_size', type=int, default=128, help='batch size')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.1, help='init learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "parser.add_argument('--weight_decay', type=float, default=3e-5, help='weight decay')\n",
    "parser.add_argument('--report_freq', type=float, default=100, help='report frequency')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu device id')\n",
    "parser.add_argument('--epochs', type=int, default=250, help='num of training epochs')\n",
    "parser.add_argument('--init_channels', type=int, default=48, help='num of init channels')\n",
    "parser.add_argument('--layers', type=int, default=14, help='total number of layers')\n",
    "parser.add_argument('--auxiliary', action='store_true', default=False, help='use auxiliary tower')\n",
    "parser.add_argument('--auxiliary_weight', type=float, default=0.4, help='weight for auxiliary loss')\n",
    "parser.add_argument('--drop_path_prob', type=float, default=0, help='drop path probability')\n",
    "parser.add_argument('--save', type=str, default='EXP', help='experiment name')\n",
    "parser.add_argument('--seed', type=int, default=0, help='random seed')\n",
    "parser.add_argument('--arch', type=str, default='DARTS', help='which architecture to use')\n",
    "parser.add_argument('--grad_clip', type=float, default=5., help='gradient clipping')\n",
    "parser.add_argument('--label_smooth', type=float, default=0.1, help='label smoothing')\n",
    "parser.add_argument('--gamma', type=float, default=0.97, help='learning rate decay')\n",
    "parser.add_argument('--decay_period', type=int, default=1, help='epochs between two learning rate decays')\n",
    "parser.add_argument('--parallel', action='store_true', default=False, help='data parallelism')\n",
    "args = parser.parse_args()\n",
    "\n",
    "args.save = 'eval-{}-{}'.format(args.save, time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "utils.create_exp_dir(args.save, scripts_to_save=glob.glob('*.py'))\n",
    "\n",
    "log_format = '%(asctime)s %(message)s'\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(args.save, 'log.txt'))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "CLASSES = 1000\n",
    "\n",
    "\n",
    "class CrossEntropyLabelSmooth(nn.Module):\n",
    "\n",
    "  def __init__(self, num_classes, epsilon):\n",
    "    super(CrossEntropyLabelSmooth, self).__init__()\n",
    "    self.num_classes = num_classes\n",
    "    self.epsilon = epsilon\n",
    "    self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "  def forward(self, inputs, targets):\n",
    "    log_probs = self.logsoftmax(inputs)\n",
    "    targets = torch.zeros_like(log_probs).scatter_(1, targets.unsqueeze(1), 1)\n",
    "    targets = (1 - self.epsilon) * targets + self.epsilon / self.num_classes\n",
    "    loss = (-targets * log_probs).mean(0).sum()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def main():\n",
    "  if not torch.cuda.is_available():\n",
    "    logging.info('no gpu device available')\n",
    "    sys.exit(1)\n",
    "\n",
    "  np.random.seed(args.seed)\n",
    "  torch.cuda.set_device(args.gpu)\n",
    "  cudnn.benchmark = True\n",
    "  torch.manual_seed(args.seed)\n",
    "  cudnn.enabled=True\n",
    "  torch.cuda.manual_seed(args.seed)\n",
    "  logging.info('gpu device = %d' % args.gpu)\n",
    "  logging.info(\"args = %s\", args)\n",
    "\n",
    "  genotype = eval(\"genotypes.%s\" % args.arch)\n",
    "  model = Network(args.init_channels, CLASSES, args.layers, args.auxiliary, genotype)\n",
    "  if args.parallel:\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "  else:\n",
    "    model = model.cuda()\n",
    "\n",
    "  logging.info(\"param size = %fMB\", utils.count_parameters_in_MB(model))\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  criterion = criterion.cuda()\n",
    "  criterion_smooth = CrossEntropyLabelSmooth(CLASSES, args.label_smooth)\n",
    "  criterion_smooth = criterion_smooth.cuda()\n",
    "\n",
    "  optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    args.learning_rate,\n",
    "    momentum=args.momentum,\n",
    "    weight_decay=args.weight_decay\n",
    "    )\n",
    "\n",
    "  traindir = os.path.join(args.data, 'train')\n",
    "  validdir = os.path.join(args.data, 'val')\n",
    "  normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "  train_data = dset.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "      transforms.RandomResizedCrop(224),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.ColorJitter(\n",
    "        brightness=0.4,\n",
    "        contrast=0.4,\n",
    "        saturation=0.4,\n",
    "        hue=0.2),\n",
    "      transforms.ToTensor(),\n",
    "      normalize,\n",
    "    ]))\n",
    "  valid_data = dset.ImageFolder(\n",
    "    validdir,\n",
    "    transforms.Compose([\n",
    "      transforms.Resize(256),\n",
    "      transforms.CenterCrop(224),\n",
    "      transforms.ToTensor(),\n",
    "      normalize,\n",
    "    ]))\n",
    "\n",
    "  train_queue = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=args.batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "  valid_queue = torch.utils.data.DataLoader(\n",
    "    valid_data, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=4)\n",
    "\n",
    "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, args.decay_period, gamma=args.gamma)\n",
    "\n",
    "  best_acc_top1 = 0\n",
    "  for epoch in range(args.epochs):\n",
    "    scheduler.step()\n",
    "    logging.info('epoch %d lr %e', epoch, scheduler.get_lr()[0])\n",
    "    model.drop_path_prob = args.drop_path_prob * epoch / args.epochs\n",
    "\n",
    "    train_acc, train_obj = train(train_queue, model, criterion_smooth, optimizer)\n",
    "    logging.info('train_acc %f', train_acc)\n",
    "\n",
    "    valid_acc_top1, valid_acc_top5, valid_obj = infer(valid_queue, model, criterion)\n",
    "    logging.info('valid_acc_top1 %f', valid_acc_top1)\n",
    "    logging.info('valid_acc_top5 %f', valid_acc_top5)\n",
    "\n",
    "    is_best = False\n",
    "    if valid_acc_top1 > best_acc_top1:\n",
    "      best_acc_top1 = valid_acc_top1\n",
    "      is_best = True\n",
    "\n",
    "    utils.save_checkpoint({\n",
    "      'epoch': epoch + 1,\n",
    "      'state_dict': model.state_dict(),\n",
    "      'best_acc_top1': best_acc_top1,\n",
    "      'optimizer' : optimizer.state_dict(),\n",
    "      }, is_best, args.save)\n",
    "\n",
    "\n",
    "def train(train_queue, model, criterion, optimizer):\n",
    "  objs = utils.AvgrageMeter()\n",
    "  top1 = utils.AvgrageMeter()\n",
    "  top5 = utils.AvgrageMeter()\n",
    "  model.train()\n",
    "\n",
    "  for step, (input, target) in enumerate(train_queue):\n",
    "    target = target.cuda(async=True)\n",
    "    input = input.cuda()\n",
    "    input = Variable(input)\n",
    "    target = Variable(target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    logits, logits_aux = model(input)\n",
    "    loss = criterion(logits, target)\n",
    "    if args.auxiliary:\n",
    "      loss_aux = criterion(logits_aux, target)\n",
    "      loss += args.auxiliary_weight*loss_aux\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\n",
    "    optimizer.step()\n",
    "\n",
    "    prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n",
    "    n = input.size(0)\n",
    "    objs.update(loss.data[0], n)\n",
    "    top1.update(prec1.data[0], n)\n",
    "    top5.update(prec5.data[0], n)\n",
    "\n",
    "    if step % args.report_freq == 0:\n",
    "      logging.info('train %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n",
    "\n",
    "  return top1.avg, objs.avg\n",
    "\n",
    "\n",
    "def infer(valid_queue, model, criterion):\n",
    "  objs = utils.AvgrageMeter()\n",
    "  top1 = utils.AvgrageMeter()\n",
    "  top5 = utils.AvgrageMeter()\n",
    "  model.eval()\n",
    "\n",
    "  for step, (input, target) in enumerate(valid_queue):\n",
    "    input = Variable(input, volatile=True).cuda()\n",
    "    target = Variable(target, volatile=True).cuda(async=True)\n",
    "\n",
    "    logits, _ = model(input)\n",
    "    loss = criterion(logits, target)\n",
    "\n",
    "    prec1, prec5 = utils.accuracy(logits, target, topk=(1, 5))\n",
    "    n = input.size(0)\n",
    "    objs.update(loss.data[0], n)\n",
    "    top1.update(prec1.data[0], n)\n",
    "    top5.update(prec5.data[0], n)\n",
    "\n",
    "    if step % args.report_freq == 0:\n",
    "      logging.info('valid %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n",
    "\n",
    "  return top1.avg, top5.avg, objs.avg\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
