{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from operations import *\n",
    "from torch.autograd import Variable\n",
    "from utils import drop_path\n",
    "\n",
    "\n",
    "class Cell(nn.Module):\n",
    "\n",
    "  def __init__(self, genotype, C_prev_prev, C_prev, C, reduction, reduction_prev):\n",
    "    super(Cell, self).__init__()\n",
    "    print(C_prev_prev, C_prev, C)\n",
    "\n",
    "    if reduction_prev:\n",
    "      self.preprocess0 = FactorizedReduce(C_prev_prev, C)\n",
    "    else:\n",
    "      self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 0)\n",
    "    self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 0)\n",
    "    \n",
    "    if reduction:\n",
    "      op_names, indices = zip(*genotype.reduce)\n",
    "      concat = genotype.reduce_concat\n",
    "    else:\n",
    "      op_names, indices = zip(*genotype.normal)\n",
    "      concat = genotype.normal_concat\n",
    "    self._compile(C, op_names, indices, concat, reduction)\n",
    "\n",
    "  def _compile(self, C, op_names, indices, concat, reduction):\n",
    "    assert len(op_names) == len(indices)\n",
    "    self._steps = len(op_names) // 2\n",
    "    self._concat = concat\n",
    "    self.multiplier = len(concat)\n",
    "\n",
    "    self._ops = nn.ModuleList()\n",
    "    for name, index in zip(op_names, indices):\n",
    "      stride = 2 if reduction and index < 2 else 1\n",
    "      op = OPS[name](C, stride, True)\n",
    "      self._ops += [op]\n",
    "    self._indices = indices\n",
    "\n",
    "  def forward(self, s0, s1, drop_prob):\n",
    "    s0 = self.preprocess0(s0)\n",
    "    s1 = self.preprocess1(s1)\n",
    "\n",
    "    states = [s0, s1]\n",
    "    for i in range(self._steps):\n",
    "      h1 = states[self._indices[2*i]]\n",
    "      h2 = states[self._indices[2*i+1]]\n",
    "      op1 = self._ops[2*i]\n",
    "      op2 = self._ops[2*i+1]\n",
    "      h1 = op1(h1)\n",
    "      h2 = op2(h2)\n",
    "      if self.training and drop_prob > 0.:\n",
    "        if not isinstance(op1, Identity):\n",
    "          h1 = drop_path(h1, drop_prob)\n",
    "        if not isinstance(op2, Identity):\n",
    "          h2 = drop_path(h2, drop_prob)\n",
    "      s = h1 + h2\n",
    "      states += [s]\n",
    "    return torch.cat([states[i] for i in self._concat], dim=1)\n",
    "\n",
    "\n",
    "class AuxiliaryHeadCIFAR(nn.Module):\n",
    "\n",
    "  def __init__(self, C, num_classes):\n",
    "    \"\"\"assuming input size 8x8\"\"\"\n",
    "    super(AuxiliaryHeadCIFAR, self).__init__()\n",
    "    self.features = nn.Sequential(\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.AvgPool2d(5, stride=3, padding=0, count_include_pad=False), # image size = 2 x 2\n",
    "      nn.Conv2d(C, 128, 1, bias=False),\n",
    "      nn.BatchNorm2d(128),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(128, 768, 2, bias=False),\n",
    "      nn.BatchNorm2d(768),\n",
    "      nn.ReLU(inplace=True)\n",
    "    )\n",
    "    self.classifier = nn.Linear(768, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = self.classifier(x.view(x.size(0),-1))\n",
    "    return x\n",
    "\n",
    "\n",
    "class AuxiliaryHeadImageNet(nn.Module):\n",
    "\n",
    "  def __init__(self, C, num_classes):\n",
    "    \"\"\"assuming input size 14x14\"\"\"\n",
    "    super(AuxiliaryHeadImageNet, self).__init__()\n",
    "    self.features = nn.Sequential(\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.AvgPool2d(5, stride=2, padding=0, count_include_pad=False),\n",
    "      nn.Conv2d(C, 128, 1, bias=False),\n",
    "      nn.BatchNorm2d(128),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(128, 768, 2, bias=False),\n",
    "      # NOTE: This batchnorm was omitted in my earlier implementation due to a typo.\n",
    "      # Commenting it out for consistency with the experiments in the paper.\n",
    "      # nn.BatchNorm2d(768),\n",
    "      nn.ReLU(inplace=True)\n",
    "    )\n",
    "    self.classifier = nn.Linear(768, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = self.classifier(x.view(x.size(0),-1))\n",
    "    return x\n",
    "\n",
    "\n",
    "class NetworkCIFAR(nn.Module):\n",
    "\n",
    "  def __init__(self, C, num_classes, layers, auxiliary, genotype):\n",
    "    super(NetworkCIFAR, self).__init__()\n",
    "    self._layers = layers\n",
    "    self._auxiliary = auxiliary\n",
    "\n",
    "    stem_multiplier = 3\n",
    "    C_curr = stem_multiplier*C\n",
    "    self.stem = nn.Sequential(\n",
    "      nn.Conv2d(3, C_curr, 3, padding=1, bias=False),\n",
    "      nn.BatchNorm2d(C_curr)\n",
    "    )\n",
    "    \n",
    "    C_prev_prev, C_prev, C_curr = C_curr, C_curr, C\n",
    "    self.cells = nn.ModuleList()\n",
    "    reduction_prev = False\n",
    "    for i in range(layers):\n",
    "      if i in [layers//3, 2*layers//3]:\n",
    "        C_curr *= 2\n",
    "        reduction = True\n",
    "      else:\n",
    "        reduction = False\n",
    "      cell = Cell(genotype, C_prev_prev, C_prev, C_curr, reduction, reduction_prev)\n",
    "      reduction_prev = reduction\n",
    "      self.cells += [cell]\n",
    "      C_prev_prev, C_prev = C_prev, cell.multiplier*C_curr\n",
    "      if i == 2*layers//3:\n",
    "        C_to_auxiliary = C_prev\n",
    "\n",
    "    if auxiliary:\n",
    "      self.auxiliary_head = AuxiliaryHeadCIFAR(C_to_auxiliary, num_classes)\n",
    "    self.global_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "    self.classifier = nn.Linear(C_prev, num_classes)\n",
    "\n",
    "  def forward(self, input):\n",
    "    logits_aux = None\n",
    "    s0 = s1 = self.stem(input)\n",
    "    for i, cell in enumerate(self.cells):\n",
    "      s0, s1 = s1, cell(s0, s1, self.drop_path_prob)\n",
    "      if i == 2*self._layers//3:\n",
    "        if self._auxiliary and self.training:\n",
    "          logits_aux = self.auxiliary_head(s1)\n",
    "    out = self.global_pooling(s1)\n",
    "    logits = self.classifier(out.view(out.size(0),-1))\n",
    "    return logits, logits_aux\n",
    "\n",
    "\n",
    "class NetworkImageNet(nn.Module):\n",
    "\n",
    "  def __init__(self, C, num_classes, layers, auxiliary, genotype):\n",
    "    super(NetworkImageNet, self).__init__()\n",
    "    self._layers = layers\n",
    "    self._auxiliary = auxiliary\n",
    "\n",
    "    self.stem0 = nn.Sequential(\n",
    "      nn.Conv2d(3, C // 2, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "      nn.BatchNorm2d(C // 2),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(C // 2, C, 3, stride=2, padding=1, bias=False),\n",
    "      nn.BatchNorm2d(C),\n",
    "    )\n",
    "\n",
    "    self.stem1 = nn.Sequential(\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(C, C, 3, stride=2, padding=1, bias=False),\n",
    "      nn.BatchNorm2d(C),\n",
    "    )\n",
    "\n",
    "    C_prev_prev, C_prev, C_curr = C, C, C\n",
    "\n",
    "    self.cells = nn.ModuleList()\n",
    "    reduction_prev = True\n",
    "    for i in range(layers):\n",
    "      if i in [layers // 3, 2 * layers // 3]:\n",
    "        C_curr *= 2\n",
    "        reduction = True\n",
    "      else:\n",
    "        reduction = False\n",
    "      cell = Cell(genotype, C_prev_prev, C_prev, C_curr, reduction, reduction_prev)\n",
    "      reduction_prev = reduction\n",
    "      self.cells += [cell]\n",
    "      C_prev_prev, C_prev = C_prev, cell.multiplier * C_curr\n",
    "      if i == 2 * layers // 3:\n",
    "        C_to_auxiliary = C_prev\n",
    "\n",
    "    if auxiliary:\n",
    "      self.auxiliary_head = AuxiliaryHeadImageNet(C_to_auxiliary, num_classes)\n",
    "    self.global_pooling = nn.AvgPool2d(7)\n",
    "    self.classifier = nn.Linear(C_prev, num_classes)\n",
    "\n",
    "  def forward(self, input):\n",
    "    logits_aux = None\n",
    "    s0 = self.stem0(input)\n",
    "    s1 = self.stem1(s0)\n",
    "    for i, cell in enumerate(self.cells):\n",
    "      s0, s1 = s1, cell(s0, s1, self.drop_path_prob)\n",
    "      if i == 2 * self._layers // 3:\n",
    "        if self._auxiliary and self.training:\n",
    "          logits_aux = self.auxiliary_head(s1)\n",
    "    out = self.global_pooling(s1)\n",
    "    logits = self.classifier(out.view(out.size(0), -1))\n",
    "    return logits, logits_aux\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
